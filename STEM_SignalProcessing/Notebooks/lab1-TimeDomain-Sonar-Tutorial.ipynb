{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Time Domain Sonar Lab\n",
    "\n",
    "### Written by Miki Lustig and Frank Ong 2016\n",
    "#### Edited, debugged, and ported to Raspberry Pi by Nick Antipa, Li-Hao Yeh, and Miki Lustig 2018\n",
    "##### Updated by Alan Dong, Gautam Gunjala, and Josh Sans 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will interact with physical time-domain signals. The first part will involve generating and recording sounds on a laptop. We will use a linear chirp signal to characterize the response of the speaker-microphone system and look at detecting signals using cross-correlation.\n",
    "In the second part, we will build on part one and use the speaker-microphone system to develop a simple sonar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import functions and libraries\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import *\n",
    "from scipy import signal\n",
    "from numpy import *\n",
    "import sounddevice as sd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Chirping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you will use the the Raspberry Pi equipped with a sound extension, a USB-powered speaker and a microphone. When playing a sound and recording, the signal goes through several systems. In particular it goes through the response of the sound extension output, the speaker, the room we are in, the response of the microphone, and the receive part of the sound extension.\n",
    "\n",
    "A linear chirp is a signal in which the frequency increases linearly with time. In this assignment we will generate a chirp signal and use it to measure the amplitude of the frequency response of our speaker-room-microphone system. This lab will work best in a quiet environment. We recommend that you execute the lab at home or in a quiet place before submitting it.\n",
    "\n",
    "An instantaneous frequency is defined as the derivative of the phase of a signal, $f = \\frac{1}{2\\pi} \\frac{d\\phi (t)}{ dt} $. For example, the instantaneous frequency of $\\cos(\\phi(t))=\\cos(2\\pi f_0 t)$ is  \n",
    "\n",
    "$$f = \\frac{d\\phi (t)}{2\\pi dt}  = f_0$$ \n",
    "\n",
    "\n",
    "For a linear chirp, the frequency changes linearly over time. The instantaneous frequency is therefore defined as \n",
    "\n",
    "<center>$$ f(t) = f_0 + kt. $$</center>\n",
    "\n",
    "\n",
    "So,  \n",
    "\n",
    "<center>$$ x(t) = \\sin(2\\pi\\int_0^t f(t')dt') = \\sin(2\\pi\\int_o^t(f_0+kt')dt') = \\sin(2\\pi(f_0+\\frac{k}{2}t)t) $$</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I, Task I: Generating the Chirp\n",
    "\n",
    "Generate a 10 second long chirp signal, sampled at 48,000 Hz with a frequency range of 20 Hz to 20,000 Hz. Set the magnitude of the chirp to 0.5. This will help prevent non-linearities when we play the sound later. \n",
    "\n",
    "* Given $T$=total time length, $f_0$=start frequency, $f_1$ = end frequency, derive a formula $f(t)$ for the frequency sweep.\n",
    "* Find the formula for the phase by integrating $\\phi(t) = 2\\pi\\int_0^T f(t)dt$ to get the phase function.\n",
    "\n",
    "Now, \n",
    "* Set the sample-rate frequency `fs = 48000` Hz\n",
    "* Generate a time index from `t = 0` s to `t = 10` s with sampling rate of 48,000 Hz\n",
    "* Generate a vector of phase vs time: `phi_of_t`  (  $\\phi(t)$ )\n",
    "* Generate the chirp function `s_chirp` with amplitude of 0.5 by plugging the phase into a sinusoid. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 48000.0\n",
    "f0 = 20.0\n",
    "f1 = 20000.0\n",
    "T = 10.0\n",
    "\n",
    "# your code here:\n",
    "\n",
    "# generate time index\n",
    "t = r_[0:T:(1/fs)]\n",
    "\n",
    "# generate chirp signal\n",
    "k = (f1-f0)/T\n",
    "phi_of_t = 2*pi*(f0 + k/2*t)*t\n",
    "s_chirp = 0.5*sin(phi_of_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the first 0.5 seconds of the chirp (`s_chirp`), you will notice that the carrier frequency increases and that the chirp has a constant envelope. To get a nice figure, make sure the aspect ratio of the figure is height/width = 0.2 . Label the axis and figure appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the aspect ratio such that the image is wide\n",
    "width, height = figaspect(0.2)\n",
    "fig = figure(figsize=(width,height))\n",
    "\n",
    "# your code here:\n",
    "plt.plot(t[t<0.5], s_chirp[t<0.5])\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Chirp signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the magnitude frequency response of the sequence from 0 to $\\pi$ using the function `signal.freqz`. Note that the digital frequency range represents a physical frequency range of 0 Hz to 24,000 Hz. To get a nice figure, make sure the aspect ratio of the figure is height/width = 0.2. Label the axis and figure appropriately. \n",
    "\n",
    "The `signal.freqz` function on the Pi is very slow -- be patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate frequency response of chirp\n",
    "w, S_chirp = signal.freqz(s_chirp, worN=512)\n",
    "\n",
    "# generate frequency index\n",
    "f = w/pi*fs/2 # convert from digital frequency to physical frequency\n",
    "# f = r_[0:1:1/512] * fs/2\n",
    "\n",
    "# plot\n",
    "width, height = plt.figaspect(0.2)\n",
    "fig = plt.figure(figsize=(width,height))\n",
    "plt.plot(f, abs(S_chirp))\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Frequency response of chirp signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the chirp is an appropriate signal to measure the magnitude frequency response of a system?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "A linear chirp sweeps all frequencies within its bandwidth. The definition of a frequency response is the response of a system to a constant frequency input. If the chirp is slow enough, then it could be considered to be a series of constant frequency inputs. By measuring the resulting (approximately) constant frequency outputs, we can obtain the system's frequency response!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I, Task II: Playing and Recording the Chirp\n",
    "Now, we will play the sound of the chirp on our speaker and simultaneously record using the microphone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Playing and recording audio:__\n",
    "\n",
    "* Run the following code. It is an example of how to play and record sound at the same time using the `sounddevice` package.\n",
    "\n",
    "The resulting received sequence will be stored in the variable `rcv_chirp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default sample rate and number of channels. \n",
    "\n",
    "sd.default.samplerate = 48000\n",
    "sd.default.channels = 1\n",
    "rcv_chirp = sd.playrec(s_chirp, fs, channels=1, blocking=False) # play the chirp\n",
    "\n",
    "rcv_chirp = rcv_chirp.reshape((rcv_chirp.shape[0],)) # reshape the vector for proper transform later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv_chirp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the frequency response of the received sequence. \n",
    "* Also, plot the absolute value of the received signal. Plotting the absolute value (sort of) displays the envelope of the chirp. \n",
    "\n",
    "Label the figures and use an aspect ratio of height/width = 0.2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot chirp response\n",
    "\n",
    "# generate frequency response of chirp\n",
    "w, RCV_chirp = signal.freqz(rcv_chirp, worN=512)\n",
    "\n",
    "# generate frequency indices\n",
    "f = w/pi*fs/2\n",
    "\n",
    "# generate time indices\n",
    "t = r_[0.0:len(rcv_chirp)]/fs\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.2)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(f, abs(RCV_chirp))\n",
    "plt.title(\"Frequency response of the transceived chirp\")\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(t, abs(rcv_chirp))\n",
    "plt.title(\"Absolute value of transceived chirp\");\n",
    "plt.xlabel(\"Time [s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Look at your results. What is the implicit assumption we are making in order to claim that the result is a frequency response? \n",
    "(HINT: consider the case when the chirp is very short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "What is interesting is that the time response of the chirp is similar to the frequency response. This makes perfect sense, since for a chirp, frequency is dependent on time. The implicit assumption that we are making is that the time effects in the room are much faster than the sweep of the chirp, so for each frequency we get the approximate steady-state response. If the chirp was much faster, we would have seen echoes coming back from reflecting surfaces, which will show up at different times. Then the DTFT of the transceived chirp would include these echoes, thus interfering with the frequency response estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I, Task III: Envelope Detection with Hilbert Transform. \n",
    "The absolute value of the result \"sort of\" displays the envelope; however, it is still modulated by the (now rectified) frequency sweep carrier. If we write down the response, it can be expressed approximately as \n",
    "\n",
    "$$y[n] = |H[n]| \\sin(2\\pi (f_0 +k[n*T])nT + \\angle H[n])$$\n",
    "\n",
    "where $|H[n]|$ is the frequency response for the instantaneous frequency at the nth sample and $\\angle H[n]$ is its phase response. \n",
    "\n",
    "The reason that it is only an approximation is that there is an inherent assumption that we do not look at transient effects, only the steady state effect for each frequency. This is a good approximation because our chirp is very slow compared to the propagation of sound in the room. \n",
    "\n",
    "One way to get the envelope $|H[n]|$ is to convert it to its analytic signal. The analytic signal $x_a(t)$ of signal $x(t)$ is:\n",
    "\n",
    "$$x_a = F^{-1}(F(x)\\cdot 2U) = x + j y$$\n",
    "\n",
    "where $F$ is the Fourier transform, $U$ the unit step function,\n",
    "and $y$ *is* the Hilbert transform of $x$. In other words, the negative half of the frequency spectrum is zeroed\n",
    "out, turning the real-valued signal into a complex signal. This is similar to the question in HW2!\n",
    "\n",
    "The analytic signal of the received chirp will then be: \n",
    "\n",
    "$$ y_a[n] = |H[n]|e^{j2\\pi (f_0 +k[n*T])nT + \\angle H[n]} $$\n",
    "\n",
    "The envelope can be detected by taking the magnitude. \n",
    "(The analytic function of $y$ seems to have one more phase shift $\\pi/2$ since it is a $\\sin$ function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the analytic signal by using the function `signal.hilbert` and plot its absolute value. Note that the discrete Hilbert Transform is not perfect, since it uses FIR filtering. This will show up as ripple in the envelope.\n",
    "\n",
    "* Label the figures and use an aspect ratio of height/width = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your lovely code here:\n",
    "rcv_chirp_a = signal.hilbert(rcv_chirp)\n",
    "t = r_[0.0:len(rcv_chirp_a)]/fs\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.2)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(t, abs(rcv_chirp_a))\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Envelope Amplitude\")\n",
    "plt.title(\"Envelope of the transcieved chirp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I, Task IV: Autocorrelation Properties of the Chirp:\n",
    "\n",
    "In Part II of the lab, we will be sending and receiving chirp pulses to estimate delays between the tranceived pulses. This is done by cross-correlating / matched filtering the received signal with the known chirp pulse to detect the echoes. In this task, we will investigate the correlation properties of the chirp.\n",
    "\n",
    "A cross-correlation is defined as:\n",
    "\n",
    "$$ R_{xy}[n] = \\sum_{m=-\\infty}^\\infty x[m]y^*[m-n] = (x[m]*y^*[-m])[n]$$\n",
    "\n",
    "where $y^*[-m]$ is the complex conjugate of $y[-m]$. This is similar to a convolution, but without flipping one of the signals. It can be implemented using a convolution as shown above. In general, the more correlated the two signals are at position $n$, the higher the value will be. That's why it is useful in a sonar system.\n",
    "\n",
    "#### Matched Filter \n",
    "When we look for a very specific shape in a signal, we can compute a cross-correlation between the signal and the shape we are interested in. In that case, the operation of the cross-correlation is also called a matched filter -- i.e. correlating with a filter that is matched to the shape we look for.\n",
    "\n",
    "Because we will be doing cross-correlations between a chirp pulse and its echoes, it is useful to look at the autocorrelation, which is basically a cross-correlation of the signal with itself. A discrete autocorrelation of a signal is defined as: \n",
    "\n",
    "$$ R_{xx}[n] = \\sum_{m=-\\infty}^\\infty x[m]x^*[m-n] = (x[m]*x^*[-m])[n]$$ \n",
    "\n",
    "The chirp has a very nice property that its autocorrelation is very narrow. Since the spread of the resulting correlation determines the time resolution of detection, the width of the autocorrelation is important. This property is called pulse compression and is widely considered in radar design. Random noise and some other pseudo-random sequences also possess this property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate a 512 sample chirp pulse with a frequency sweep from 17 kHz to 18 kHz and sampling rate fs = 48000 Hz. \n",
    "* Validate its frequency response by plotting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your beautiful code here:\n",
    "fs = 48e3\n",
    "N = 512\n",
    "T = N/fs\n",
    "t = r_[0.0:N]/fs\n",
    "f0 = 17e3\n",
    "f1 = 18e3\n",
    "\n",
    "# generate chirp signal\n",
    "k = (f1-f0)/T\n",
    "phi_of_t = 2*pi*(f0 + k/2*t)*t\n",
    "s_chirp = sin(phi_of_t)\n",
    "\n",
    "# generate frequency response of chirp\n",
    "w, S_chirp = signal.freqz(s_chirp, worN=512)\n",
    "\n",
    "# generate frequency index\n",
    "f = w/pi*fs/2\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.1)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(f, abs(S_chirp))\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Frequency response of chirp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Compute the autocorrelation of the chirp using discrete convolution, either with `signal.convolve` or `signal.fftconvolve`. Remember that you have to flip the signal since convolution does that already. You can flip a signal `x` by doing `x[::-1]`. Use `mode=\"full\"` for convolution.\n",
    "* Plot the autocorrelation. Your plot should be spiky because we did not do envolope detection yet. Use miliseconds for the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your fantastic code here:\n",
    "\n",
    "# compute autocorrelation\n",
    "chirp_acorr = signal.convolve(s_chirp, conj(s_chirp[::-1]), mode=\"full\")\n",
    "t = (r_[-len(chirp_acorr)/2.0:len(chirp_acorr)/2.0] + 0.5) / fs * 1e3\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.2)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(t, chirp_acorr)\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Autocorrelation of chirp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar way as we did before, it is possible to recover the envelope of the autocorrelation by performing the cross-correlation with the analytic signal and then taking the absolute value. In this case, we know exactly what the analytic function is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate `s_chirp_a`, the analytic function of the chirp by computing: `s_chirp_a = exp(1j*phi_of_t)`. Perform the cross-correlation between `s_chirp_a` and `s_chirp` and show the envelope. As stated before, this could also be called a matched filter. \n",
    "* Measure the full-width at half max (FWHM) of the main lobe of the autocorrelation. \n",
    "* Comment on the FWHM of the main lobe of the matched filter with respect to the duration of the pulse. That ratio is also called pulse compression.  For simplicity, normalize the plot such that the maximum is 1, but record the maximum value of the autocorrelation and display it in the title of the figure.  \n",
    "\n",
    "Use the pragma ``%matplotlib notebook`` for making the figure interactive, and ``plt.grid('on')`` for displaying a grid.\n",
    "\n",
    "Use milliseconds for the x-axis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# your nice script to produce beautiful chirps, cross-correlations, and figures here:\n",
    "\n",
    "# compute autocorrelation and envelope\n",
    "s_chirp_a = exp(1j*phi_of_t)\n",
    "chirp_acorr = signal.convolve(s_chirp, conj(s_chirp_a[::-1]))\n",
    "max_chirp_acorr = max(abs(chirp_acorr))\n",
    "tt = (r_[-len(chirp_acorr)/2.0:len(chirp_acorr)/2.0] + 0.5) / fs * 1e3\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.3)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(tt, abs(chirp_acorr)/max_chirp_acorr)\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Envelope Amplitude\")\n",
    "plt.title(\"Autocorrelation envelope of chirp, max=%f\" %max_chirp_acorr)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here:\n",
    "The main lobe of the matched filter has a FWHM of ~1.23 ms while the original pulse has a duration of ~10.67 ms. Effectively, the pulse is compressed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look at why the chirp pulse is better for cross-correlation detection than a pure tone.\n",
    "- Repeat Task IV for:\n",
    " 1. A constant frequency of 17,000 Hz, 512 samples in length. \n",
    " 2. A chirp with a frequency sweep from 16,500 Hz to 17,500 Hz (1 kHz bandwidth), 512 samples in length.  \n",
    " 3. A chirp with a frequency sweep from 15,000 Hz to 19,000 Hz (4 kHz bandwidth), 512 samples in length.\n",
    "- Compare the widths of the main lobes (full width at half max). How much \"Pulse Compression\" are you getting by using a chirp for detection compared to a single frequency pulse?\n",
    "- What is the approximate bandwidth of the pure frequency pulse and what is the bandwidth of the chirp pulses? Comment on the tradeoff between bandwidth and pulse compression.\n",
    "- What is the maximum autocorrelation for each pulse?\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your brilliant code here:\n",
    "fs = 48e3\n",
    "N = 512\n",
    "T = N/fs\n",
    "t = r_[0.0:N]/fs\n",
    "\n",
    "# generate pure tone\n",
    "f0 = 17e3\n",
    "s_tone = sin(2*pi*f0*t)\n",
    "s_tone_a = exp(1j*2*pi*f0*t)\n",
    "cross_corr_1 = signal.convolve(s_tone, conj(s_tone_a[::-1]))\n",
    "tt = (r_[-len(cross_corr_1)/2.0:len(cross_corr_1)/2.0] + 0.5) / fs * 1e3\n",
    "\n",
    "# generate lower bandwidth chirp signal\n",
    "f0 = 16.5e3\n",
    "f1 = 17.5e3\n",
    "k = (f1-f0)/T\n",
    "phi_of_t = 2*pi*(f0 + k/2*t)*t\n",
    "s_chirp = sin(phi_of_t)\n",
    "s_chirp_a = exp(1j*phi_of_t)\n",
    "cross_corr_2 = signal.convolve(s_chirp, conj(s_chirp_a[::-1]))\n",
    "\n",
    "# generate higher bandwidth chirp signal\n",
    "f0 = 15e3\n",
    "f1 = 19e3\n",
    "k = (f1-f0)/T\n",
    "phi_of_t = 2*pi*(f0 + k/2*t)*t\n",
    "s_chirp = sin(phi_of_t)\n",
    "s_chirp_a = exp(1j*phi_of_t)\n",
    "cross_corr_3 = signal.convolve(s_chirp, conj(s_chirp_a[::-1]))\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.3)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(tt, abs(cross_corr_1)/max(abs(cross_corr_1)))\n",
    "plt.plot(tt, abs(cross_corr_2)/max(abs(cross_corr_2)))\n",
    "plt.plot(tt, abs(cross_corr_3)/max(abs(cross_corr_3)))\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Envelope Amplitude\")\n",
    "plt.title(\"Effect of pulse bandwidth on autocorrelation envelope\")\n",
    "plt.legend((\"Tone, max=%i\" %max(abs(cross_corr_1)), \"1 kHz chirp, max=%i\" %max(abs(cross_corr_2)), \"4 kHz chirp, max=%i\" %max(abs(cross_corr_3))))\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer and interpretations here:\n",
    "The FWHM of the autocorrelation envelope of the constant frequency signal is \\~10.66 ms, the same as its pulse duration. The main lobe for the 1 kHz bandwidth chirp has a FWHM of \\~1.23 ms and the 4 kHz chirp has a FWHM of \\~0.30 ms. Their pulse compression ratios are ~8.67 and ~35.3, respectively.\n",
    "At the same time, the bandwidth of the constant frequency pulse is approximately 1/(its duration) = ~94 Hz, and the bandwidths of the chirps are 1 kHz and 4 kHz -- these are inversely proportional to the main lobe widths!\n",
    "So, you can't be compact in one domain without expanding in the other...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, repeat Task IV for a chirp with a frequency sweep from 16,500 Hz to 17,500 Hz, 256 samples in length\n",
    "- Compare the width of the main lobe (full width at half max) to the previous case of 16,500 Hz - 17,500 Hz, 512 samples in length.\n",
    "- Compare the maximum autocorrelation values as well.\n",
    "\n",
    "What's the effect of having more bandwidth? What's the effect of having longer/shorter pulses?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your amazing code here:\n",
    "fs = 48e3\n",
    "N = 256\n",
    "T = N/fs\n",
    "t = r_[0.0:N]/fs\n",
    "\n",
    "# generate chirp signal\n",
    "f0 = 16.5e3\n",
    "f1 = 17.5e3\n",
    "k = (f1-f0)/T\n",
    "phi_of_t = 2*pi*(f0 + k/2*t)*t\n",
    "s_chirp = sin(phi_of_t)\n",
    "s_chirp_a = exp(1j*phi_of_t)\n",
    "cross_corr_4 = signal.convolve(s_chirp, conj(s_chirp_a[::-1]))\n",
    "tt2 = (r_[-len(cross_corr_4)/2.0:len(cross_corr_4)/2.0] + 0.5) / fs * 1e3\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.3)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(tt2, abs(cross_corr_4)/max(abs(cross_corr_4)))\n",
    "plt.plot(tt, abs(cross_corr_2)/max(abs(cross_corr_2)))\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Envelope Amplitude\")\n",
    "plt.title(\"Effect of pulse duration on autocorrelation envelope\")\n",
    "plt.legend((\"256-length 1 kHz chirp, max=%i\" %max(abs(cross_corr_4)), \"512-length 1 kHz chirp, max=%i\" %max(abs(cross_corr_2))))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Your answer below:\n",
    "These two chirp pulses have the same FWHM, but the one that's twice as long has twice the peak autocorrelation value. The main lobe width is proportional to the pulse bandwidth. The peak correlation value is proportional to the pulse duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with sidelobes\n",
    "As you can see, the chirp provides good pulse compression of the main lobe. However, there exist very strong sidelobes. This is because the chirp is multiplied with a rect function; that is abrupt. Instead, we will window the chirp with one of the smooth window functions to taper off the sidelobes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repeat the above for a 512-length chirp with a sweep from 16.5 kHz to 17.5 kHz, and from 15 kHz to 19 kHz. This time, multiply the chirp (and its analytic function) with a Hann window. You will find the function `signal.hann` useful. \n",
    "\n",
    "* Plot the normalized autocorrelations (in the same figure).\n",
    "* Comment on the magnitude of the sidelobes.\n",
    "* Comment on the width of the main lobes.\n",
    "* What's the tradeoff?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here:\n",
    "fs = 48e3\n",
    "N = 512\n",
    "T = N/fs\n",
    "t = r_[0.0:N]/fs\n",
    "\n",
    "# generate lower bandwidth chirp signal\n",
    "f0 = 16.5e3\n",
    "f1 = 17.5e3\n",
    "k = (f1-f0)/T\n",
    "phi_of_t = 2*pi*(f0 + k/2*t)*t\n",
    "s_chirp = sin(phi_of_t) * signal.hann(N)\n",
    "s_chirp_a = exp(1j*phi_of_t) * signal.hann(N)\n",
    "cross_corr_5 = signal.convolve(s_chirp, conj(s_chirp_a[::-1]))\n",
    "tt = (r_[-len(cross_corr_5)/2.0:len(cross_corr_5)/2.0] + 0.5) / fs * 1e3\n",
    "\n",
    "# generate higher bandwidth chirp signal\n",
    "f0 = 15e3\n",
    "f1 = 19e3\n",
    "k = (f1-f0)/T\n",
    "phi_of_t = 2*pi*(f0 + k/2*t)*t\n",
    "s_chirp = sin(phi_of_t) * signal.hann(N)\n",
    "s_chirp_a = exp(1j*phi_of_t) * signal.hann(N)\n",
    "cross_corr_6 = signal.convolve(s_chirp, conj(s_chirp_a[::-1]))\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.3)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(tt, abs(cross_corr_5)/max(abs(cross_corr_5)))\n",
    "plt.plot(tt, abs(cross_corr_6)/max(abs(cross_corr_6)))\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Envelope Amplitude\")\n",
    "plt.title(\"Effect of windowing on autocorrelation envelope\")\n",
    "plt.legend((\"Windowed 1 kHz chirp, max=%i\" %max(abs(cross_corr_5)), \"Windowed 4 kHz chirp, max=%i\" %max(abs(cross_corr_6))))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "The widths of the main lobes are approximately doubled. The FWHM for the windowed 1 kHz chirp is ~2.49 ms compared to ~1.23 ms for the unwindowed one. Likewise, the FWHM for the windowed 4 kHz chirp is ~0.65 ms compared to ~0.30 ms. Furthermore, the maximum autocorrelation values are reduced. But, the sidelobes are significantly smaller!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are now ready to proceed to the Sonar Lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Sonar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the lab we will write a simple application that implements a speaker and microphone.\n",
    "\n",
    "The basic idea is very simple and is the basis of sonar and ultrasound imaging -- objects reflect sound waves. If we send a pulse of sound, we will get reflection echoes of that pulse. Detecting the echoes and their time-of-flight will reveal their distance from the source, based on the speed of sound in air. \n",
    "\n",
    "The way we are going to implement the sonar is to generate a series of rapid pulses, and then use matched filtering to detect the returning echoes. There are many parameters in this lab that can be tweaked to get different results. We encourage you to experiment. We very much enjoyed making the lab and played quite a bit! We hope you enjoy it too. \n",
    "\n",
    "#### Instructions:\n",
    "The microphone and speaker you have are somewhat directional. Make sure that the microphone and speaker point in the same direction. You will get the best quality in a quiet room, without interference from other sources of noise!\n",
    "\n",
    "If you are getting poor results, please consult with us. \n",
    "\n",
    "This lab was inspired from an iPhone app called active-radar. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II, Task I: Generating Chirp Pulses\n",
    "\n",
    "Recall from Part I, that the width of the main lobe of the autocorrelation depends on the bandwidth of the pulse. \n",
    "For a constant frequency pulse (i.e. a pure tone), the bandwidth will be inversly proportional to its length. Short pulses are localized in time, and therefore we will be able to separate echoes from targets that are closely spaced. However, short pulses carry less energy (for the same amplitude) and this will reduce our signal-to-noise ratio (SNR) in the detection and reduce our ability to detect the targets at all. So, in summary: for constant frequency pulse, there's an inherent tradeoff between the resolution of the sonar (distinguish between close targets) and the signal-to-noise ratio. \n",
    "\n",
    "If we use a chirp pulse, we can increase the length of the pulse while also increasing the bandwidth. This will enable us to improve our SNR as well as keep the resolution of our sonar (by preserving a large bandwidth).\n",
    "\n",
    "In our implemetation we are going to design a pulsed sonar system in which we repeatedly send pulses and then listen to the returning echoes. The arrival time of the echoes will correspond to double the time-of-flight of sound propagation from our system to the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write a function that generates a chirp pulse:\n",
    "`pulse = genChirpPulse(Npulse, f0, f1, fs)`.\n",
    "\n",
    "The function will accept: `Npulse` = number of samples, `f0, f1` = starting and ending frequency and `fs` = sampling rate. The function will return the analytic function of the chirp $\\exp (j 2\\pi \\int_0^t f(t)dt )$ with amplitude 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genChirpPulse(Npulse, f0, f1, fs):\n",
    "    # Function generates an analytic function of a chirp pulse\n",
    "    # Inputs:\n",
    "    #     Npulse = pulse length in samples\n",
    "    #     f0     = starting frequency of chirp\n",
    "    #     f1     = end frequency of chirp\n",
    "    #     fs     = sampling frequency\n",
    "    # Output:\n",
    "    #     pulse  = chirp pulse\n",
    "    \n",
    "    T = Npulse/fs\n",
    "    t = np.r_[0.0:Npulse]/fs\n",
    "    k = (f1-f0)/T\n",
    "    pulse = exp(1j*2*pi*(f0 + k/2*t)*t)\n",
    "    \n",
    "    return pulse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* To validate that the function works display the pulse generated with `Npulse = 200`, `f0 = 1000`, `f1 = 8000`, `fs = 48000`. Remember the pulse is complex, so plot the real and imaginary parts separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "# your code here:\n",
    "pulse = genChirpPulse(200, 1000.0, 8000.0, 48000.0)\n",
    "t = r_[0.0:len(pulse)]/fs * 1e3\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.2)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(t, pulse.real)\n",
    "plt.plot(t, pulse.imag)\n",
    "plt.title(\"Chirp signal\")\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Amplitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generate Pulse Trains__\n",
    "\n",
    "Next, we will use the pulse generated by `genChirpPulse` and generate a pulse train.\n",
    "\n",
    "* Write a new function `ptrain = genPulseTrain(pulse, Nrep, Nseg)`\n",
    "that accepts `pulse` = a pulse generated by `genChirpPulse`,  `Nrep` = number of pulse repetitions, and `Nseg` = length of each pulse train segment (which is >= to the length of `pulse`).\n",
    "\n",
    "The function returns `ptrain` which is a vector of length `Nrep * Nseg`. (Hint: use `np.tile`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genPulseTrain(pulse, Nrep, Nseg):\n",
    "    # Function generates a pulse train from a pulse. \n",
    "    # Inputs:\n",
    "    #     pulse  = the pulse generated by genChirpPulse\n",
    "    #     Nrep   = number of pulse repetitions\n",
    "    #     Nseg   = length of pulse segment >= len(pulse)\n",
    "    # Output:\n",
    "    #     ptrain = pulse train\n",
    "    \n",
    "    seg = zeros(Nseg)\n",
    "    seg[:len(pulse)] = pulse\n",
    "    ptrain = tile(seg, Nrep)\n",
    "    \n",
    "    return ptrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II, Task II: Record Echoes of Chirp Pulse Train\n",
    "\n",
    "We now have components to generate pulses, generate a pulse train, and play and record it. Let's see what we get!\n",
    "We will start with very short pulses with a single carrier frequency. Rectangular pulses are difficult for the speaker\n",
    "to produce as they exhibit discontinuities at the beginning and the end of the pulse. Therefore we will multiply the pulses\n",
    "with a smooth window. Here, we will use a Hann window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate a `f0` = `f1` = 8 kHz, `Npulse` = 96 pulse with `fs` = 48000. Window the pulse with a Hann window. This will result in a pulse length of 2 ms. You should be able to hear this tone.\n",
    "* Plot the real and imaginary parts of the pulse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 48e3\n",
    "f0 = 8e3\n",
    "f1 = 8e3\n",
    "Npulse = 96\n",
    "\n",
    "# your code here:\n",
    "pulse_a = genChirpPulse(Npulse, f0, f1, fs) * signal.hann(Npulse)\n",
    "pulse = pulse_a.real\n",
    "t = r_[0.0:len(pulse)]/fs * 1e3\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.2)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(t, pulse)\n",
    "plt.plot(t, pulse_a.imag)\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Windowed chirp\")\n",
    "plt.legend(('real','imag'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the real part of the pulse to generate a pulse train of `Nrep` = 15 pulses, `Nseg` = 4096 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "Nrep = 15\n",
    "Nseg = 4096\n",
    "ptrain = genPulseTrain(pulse, Nrep, Nseg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Play and record the pulse train. Scale the amplitude of the pulses to 0.5. Make sure your volume is set to a maximum of 70% and look at the plot with the input pulse train and the received pulse train.\n",
    "\n",
    "Use the pragma ``%matplotlib notebook`` for interactive plots, so you can zoom in on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rcv = sd.playrec(ptrain/2.0, fs, channels=1, blocking=True)\n",
    "rcv = sd.playrec(1000*ptrain, fs, channels=1, blocking=True) \n",
    "#You may have to chance the scalar value of 1000 above to adjust the loudness (increase for louder, decrease for softer)\n",
    "\n",
    "rcv = rcv.reshape((rcv.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# your code here:\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.3)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(ptrain)\n",
    "plt.plot(rcv)\n",
    "plt.title(\"Transceived pulse train\")\n",
    "plt.legend((\"Transmitted\", \"Received\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract a single pulse from the received pulse train. You can find the starting index of the pulse from the interactive plot. Extract at least `2*Npulse` samples before the starting index and `20*Npulse` samples after using `rcv_pulse = rcv[idx-2*Npulse:idx+Npulse*20]`\n",
    "\n",
    "* Plot the received pulse. Can you see any echoes?\n",
    "\n",
    "You can disable interactivity using the pragma ``matplotlib inline``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# your code here:\n",
    "\n",
    "# find index of start pulse\n",
    "ind = argmax( abs(rcv[100::]) > 0.75*max(abs(rcv[100::])) ) + 100\n",
    "inds = r_[ind-2*Npulse:ind+20*Npulse]\n",
    "rcv_pulse = rcv[inds]\n",
    "t = r_[0.0:len(rcv)]/fs * 1e3\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.2)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(t[inds], rcv_pulse)\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Single transceived pulse (plus echoes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matched Filtering\n",
    "\n",
    "The strong pulses we see are a result of direct feedthrough from the transmitter to the receiver that do not scatter off targets. The echoes we see are a result of echoes from reflecting surfaces. The problem in our setup is that we don't know the exact delay between the transmitter and the receiver. Instead, we will assume that the travel time for sound between the speaker and the microphone is negligible and much smaller than that of reflective targets. We can then detect when the pulses start based on the direct feedthrough signal. This assumption is very good as long as your speaker is close to the microphone!\n",
    "\n",
    "We will detect both the feedthrough and echoes using matched filtering.\n",
    "\n",
    "* Write a function `Xrcv = crossCorr(rcv, pulse_a)` to calculate the cross-correlation (matched filter) of the received signal with the analytic function of the pulse.  You can use `signal.convolve` or `signal.fftconvolve`.\n",
    "* Take the absolute value of `Xrcv` to recover its envelope. Call the result `Xrcv_a`.\n",
    "\n",
    "Make sure the plot is interactive with ``matplotlib notebook``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossCorr(rcv, pulse_a):\n",
    "    # Funtion generates cross-correlation between rcv and pulse_a.\n",
    "    # Inputs:\n",
    "    #     rcv     = received signal\n",
    "    #     pulse_a = analytic pulse\n",
    "    # Output:\n",
    "    #     Xrcv    = cross-correlation between rcv and pulse_a\n",
    "    \n",
    "    Xrcv = signal.convolve(rcv, pulse_a[::-1])\n",
    "    \n",
    "    return Xrcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# your code here:\n",
    "Xrcv_a = abs(crossCorr(rcv, pulse_a))\n",
    "t = r_[0.0:len(Xrcv_a)]/fs * 1e3\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.3)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(t, Xrcv_a)\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Envelope Amplitude\")\n",
    "plt.title(\"Cross-correlation of transceived pulse train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Again, extract a single pulse from the received pulse train using the same index. Extract at least `2*Npulse` samples before the pulse and `20*Npulse` samples after. Plot the received pulse. Can you see any echoes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# find index of start pulse\n",
    "Xrcv_pulse = Xrcv_a[inds]\n",
    "t = r_[0.0:len(Xrcv_a)]/fs * 1e3\n",
    "\n",
    "# plot\n",
    "width, height = figaspect(0.2)\n",
    "fig = figure(figsize=(width,height))\n",
    "plt.plot(t[inds], Xrcv_pulse)\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Envelope Amplitude\")\n",
    "plt.title(\"Cross-correlation of single transceived pulse (plus echoes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sonar System\n",
    "\n",
    "In order to automate the system and visualize the results we need a few more components. To extract the pulses we need to know the position of the first feedthrough pulse. \n",
    "\n",
    "\n",
    "* Write a function `ind = findDelay(Xrcv_a, Nseg)` that takes the result of the matched filter and finds the index of the first feedthrough pulse. Try testing on the actual signal to check whether the function is correct. There are multiple ways of doing it. `Nseg` is not necessarily required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDelay(Xrcv, Nseg):\n",
    "    # Function finds the first pulse index.\n",
    "    # Inputs:  \n",
    "    #     Xrcv = the received matched filtered signal\n",
    "    #     Nseg = length of a segment\n",
    "    # Output:\n",
    "    #     ind  = index of the beginning of the first pulse\n",
    "    \n",
    "    ind = argmax(Xrcv[0:Nseg])\n",
    "    \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = findDelay(Xrcv_a, Nseg)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can correct for delays and detect echoes. The only thing left now is to convert the time between echoes into actual distance.\n",
    "\n",
    "If we send a pulse of sound, we will get reflection echoes of that pulse. Detecting the echoes and their time-of-flight will reveal their distance from the source, based on the speed of sound in air. The speed of sound in air is given by the following equation:\n",
    "\n",
    "$$ v_s = 331.5\\sqrt{1+T/273.15}~\\mathrm{m/s}$$ \n",
    "\n",
    "where T is the temperature in degrees Celcius. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a function `t = dist2time(dist, temperature)` that takes in the distance to the target in cm and converts it into the time in seconds between the transmitted pulse and its echo. Remember the arrival time includes the time to the target and back and therefore the time should be doubled. \n",
    "For example, for `temperature` = 20 degrees Celsius and `dist` = 400 cm, the time it takes is 0.023 s.\n",
    "\n",
    "* Create a function `dist = time2dist(t, temperature)` that takes in the time to the target in seconds and converts it into the distance in cm between the transmitted pulse and its echo. Remember the arrival time includes the time to the target and back and therefore the time should be halved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dist2time(dist, temperature=21.0):\n",
    "    # Function converts distance in cm to time in seconds.\n",
    "    # Inputs:\n",
    "    #     dist        = distance to object in cm\n",
    "    #     temperature = in Celcius\n",
    "    # Output:\n",
    "    #     t           = time in seconds between transmitted pulse and echo\n",
    "    \n",
    "    v_sound = 331.5*sqrt(1 + temperature/273.15) * 100 # in cm/s\n",
    "    t = dist/v_sound*2\n",
    "    \n",
    "    return t\n",
    "\n",
    "def  time2dist(t, temperature=21.0):\n",
    "    # Function converts time in seconds to distance in cm.\n",
    "    # Inputs:\n",
    "    #     t           = time in seconds between transmitted pulse and echo\n",
    "    #     temperature = in Celcius\n",
    "    # Output:\n",
    "    #     dist        = distance to object in cm\n",
    "    \n",
    "    v_sound = 331.5*sqrt(1 + temperature/273.15) * 100 # in cm/s\n",
    "    dist = t/2*v_sound\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A sonar (almost)\n",
    "\n",
    "* The following function will use your functions to generate pulses and display the matched filtering of each pulse as intensity of a horizontal line in an image. If nothing is moving, you will be able to see constant vertical lines representing echoes. If something is moving, you will be able to track the object's distance.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortOfASonar(Npulse, f0, f1, fs, Nrep, Nseg):\n",
    "    pulse_a = genChirpPulse(Npulse, f0, f1, fs) * signal.hann(Npulse)\n",
    "    pulse = pulse_a.real\n",
    "    ptrain = genPulseTrain(pulse, Nrep, Nseg)\n",
    "    rcv = sd.playrec(ptrain/2.0, fs, channels=1, blocking=True)\n",
    "    rcv = rcv.reshape((rcv.shape[0],))\n",
    "    Xrcv_a = abs(crossCorr(rcv, pulse_a))\n",
    "    \n",
    "    ind = findDelay(Xrcv_a, Nseg) \n",
    "    img = np.zeros((Nrep-1,Nseg))\n",
    "    img[0,:] = Xrcv_a[ind:ind+Nseg]\n",
    "    \n",
    "    # Look for peak in each pulse in the pulse train to avoid drift between transmit and receive\n",
    "    for n in range(1, Nrep-1):\n",
    "        ind2 = findDelay(Xrcv_a[ind+Nseg//2:ind+Nseg//2+Nseg], Nseg)\n",
    "        ind = ind + ind2 + Nseg//2\n",
    "        img[n,:] = Xrcv_a[ind:ind+Nseg]\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the function above to:  \n",
    "\n",
    "* Generate a pulse train of 100 pulses. Each (Hann windowed) pulse should be length `Npulse = 72` samples (1.5 ms) and a constant frequency of 8 kHz. The spacing between pulses should be 0.1 seconds (`Nseg = 4800`). \n",
    "* Display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Npulse = 72\n",
    "f0 = 8e3\n",
    "f1 = 8e3\n",
    "fs = 48e3\n",
    "Nrep = 100\n",
    "Nseg = 4800\n",
    "img = sortOfASonar(Npulse, f0, f1, fs, Nrep, Nseg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the result. Pay attention to the width of the echoes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# display up to 2.5 m, approximately 700 samples at 48000 Hz sampling rate (and 21 degrees C)\n",
    "\n",
    "vmax = 0.25 # threshold -- lower will be able to see smaller echoes\n",
    "\n",
    "plt.imshow(img[:,0:700]/max(img.ravel()), vmax=vmax, aspect=10, cmap='gray', interpolation='bilinear', extent=(0,time2dist(700/fs), Nrep*Nseg/fs, 0))\n",
    "plt.xlabel('Distance [cm]')\n",
    "plt.ylabel('Time [s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, repeat the experiment with a chirp length of `Npulse = 360` samples, and a frequency sweep from 6 kHz to 12 kHz.\n",
    "Pay attention to the resolution of the lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Npulse = 360\n",
    "f0 = 6000.0\n",
    "f1 = 12000.0\n",
    "fs = 48000.0\n",
    "Nrep = 100\n",
    "Nseg = 4800\n",
    "img = sortOfASonar(Npulse, f0, f1, fs, Nrep, Nseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# display up to 2.5 m, approximately 700 samples at 48000 Hz sampling rate (and 21 degrees C)\n",
    "\n",
    "vmax = 0.25 # threshold -- lower will be able to see smaller echoes\n",
    "\n",
    "plt.imshow(img[:,0:700]/max(img.ravel()), vmax=vmax, aspect=10, cmap='gray', interpolation='bilinear', extent=(0,time2dist(700/fs), Nrep*Nseg/fs, 0))\n",
    "plt.xlabel('Distance [cm]')\n",
    "plt.ylabel('Time [s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to repeat while moving a target -- can you see the echoes changing? Try playing with different parameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## A Real (Time) Sonar\n",
    "You now have a working sonar! It would be much easier though to play with different parameters if we automate things, so we created some wrappers for real-time plotting in a separate notebook (lab1-RealTime-Sonar). \n",
    "\n",
    "* Copy-and-paste the 5 functions you created, including `genPulseTrain()`, `genChirpPulse()`, `crossCorr()`, `findDelay()`, and `dist2time()`, to the specified code cell in the Real-Time Sonar Lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are now ready to proceed to the Real-Time Sonar Lab!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
